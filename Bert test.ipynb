{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT 預訓練模型載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (4.16.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (0.11.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: click in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\m0944018\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.16.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers. __version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel, BertTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# download bert-base-uncased model \n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load資料\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#測試先讀入其中一個資料就好\n",
    "aud1_df = pd.read_csv(\"./Pre_data/move_window/AUD/AUD1.csv\", index_col = 0)\n",
    "aud2_df = pd.read_csv(\"./Pre_data/move_window/AUD/AUD2.csv\", index_col = 0)\n",
    "aud3_df = pd.read_csv(\"./Pre_data/move_window/AUD/AUD3.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12099 entries, 0 to 12098\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           12099 non-null  object \n",
      " 1   word2vec_body  12099 non-null  object \n",
      " 2   tfidf_body     12099 non-null  object \n",
      " 3   bert_body      12099 non-null  object \n",
      " 4   source_title   12099 non-null  object \n",
      " 5   binary         12099 non-null  float64\n",
      " 6   ternary_1      12099 non-null  float64\n",
      " 7   ternary_2      12099 non-null  float64\n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 850.7+ KB\n"
     ]
    }
   ],
   "source": [
    "aud1_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2averege_bertvec(text):\n",
    "    wordvec = np.array([])\n",
    "    text_vec = np.array([])\n",
    "    word_count = 0\n",
    "                \n",
    "    for segment in eval(text):\n",
    "        if(segment != \"\" and segment != \" \"):\n",
    "            tokens = tokenizer.tokenize(segment)                #分割句字中的單字，看不懂得bert會補上萬用字元\n",
    "            token_ids = tokenizer.convert_tokens_to_ids(tokens) #將單字轉換為bert對應的詞id\n",
    "            token_ids = tf.convert_to_tensor(token_ids)         #將id轉為tensor表示(詞數,)\n",
    "            token_ids = tf.reshape(token_ids, [1, -1 ])         #reshape(1,詞數)\n",
    "\n",
    "            output = bert_model(token_ids)                      #輸入至bert模型中\\\n",
    "            segment_vec = output[0][0].numpy()                  #將tensor轉為numpy，比較好用> <\n",
    "            word_count += segment_vec.shape[0]                  #統計字數\n",
    "            wordvec = np.append(wordvec, segment_vec)           #將所有句子append到一個np.array。缺點會全部變成一維表示\n",
    "        \n",
    "    wordvec = wordvec.reshape(word_count,768)               #重塑1D->2D <字數，詞向量>\n",
    "    \n",
    "    text_vec = np.mean(wordvec,axis=0)                      #對col方向進行平均計算\n",
    "    \n",
    "    return text_vec.reshape(1,768)                          #重塑矩陣形狀為1一文本300文本向量(這是一個確保，以免形狀不對)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2_bertvec(text, max_word = 100):\n",
    "    wordvec = np.array([])\n",
    "    word_count = 0\n",
    "                \n",
    "    for segment in eval(text):\n",
    "        if(segment != \"\" and segment != \" \"):\n",
    "            tokens = tokenizer.tokenize(segment)                #分割句字中的單字，看不懂得bert會補上萬用字元\n",
    "            token_ids = tokenizer.convert_tokens_to_ids(tokens) #將單字轉換為bert對應的詞id\n",
    "            token_ids = tf.convert_to_tensor(token_ids)         #將id轉為tensor表示(詞數,)\n",
    "            token_ids = tf.reshape(token_ids, [1, -1 ])         #reshape(1,詞數)\n",
    "\n",
    "            output = bert_model(token_ids)                      #輸入至bert模型中\\\n",
    "            segment_vec = output[0][0].numpy()                  #將tensor轉為numpy，比較好用> <\n",
    "            word_count += segment_vec.shape[0]                  #統計字數\n",
    "            wordvec = np.append(wordvec, segment_vec)           #將所有句子append到一個np.array。缺點會全部變成一維表示\n",
    "        \n",
    "    wordvec = wordvec.reshape(word_count,768)               #重塑1D->2D <字數，詞向量>\n",
    "    \n",
    "    \n",
    "    if word_count > max_word:                              \n",
    "        wordvec = wordvec[0 : max_word]                     #字多就砍，保留前面\n",
    "    \n",
    "    \n",
    "    elif word_count < max_word:                             #字少就加，添加0向量，補足我們需要的大小\n",
    "        pad_num = max_word - word_count\n",
    "        filler = np.zeros((pad_num, 768))\n",
    "        wordvec =np.append(wordvec,filler,axis=0)           #這用法很重要ㄟ，很好用!!!\n",
    "    \n",
    "    return wordvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#挑選YF的來源測試。\n",
    "groupset = aud1_df.groupby(\"source_title\") #分群\n",
    "aud1_YF = groupset.get_group(\"Yahoo Finance\") #取出YF\n",
    "aud1_YF = aud1_YF.reset_index(drop=True) #重設索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"embeddings\" (type TFBertEmbeddings).\n\nValue for attr 'Tindices' of float is not in the list of allowed values: int32, int64\n\t; NodeDef: {{node ResourceGather}}; Op<name=ResourceGather; signature=resource:resource, indices:Tindices -> output:dtype; attr=batch_dims:int,default=0; attr=validate_indices:bool,default=true; attr=dtype:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true> [Op:ResourceGather]\n\nCall arguments received:\n  • input_ids=tf.Tensor(shape=(1, 0), dtype=float32)\n  • position_ids=None\n  • token_type_ids=tf.Tensor(shape=(1, 0), dtype=int32)\n  • inputs_embeds=None\n  • past_key_values_length=0\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-59d1134b20c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#計算文本向量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mbertvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbertvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext2averege_bertvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maud1_YF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bert_body\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mbertvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbertvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m768\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#使每篇文本有各自的向量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-114-9e5848cfc855>\u001b[0m in \u001b[0;36mtext2averege_bertvec\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m         \u001b[1;31m#reshape(1,詞數)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[1;33m)\u001b[0m                      \u001b[1;31m#輸入至bert模型中\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0msegment_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                  \u001b[1;31m#將tensor轉為numpy，比較好用> <\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mword_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msegment_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m                  \u001b[1;31m#統計字數\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[0;32m   1125\u001b[0m             \u001b[0mkwargs_call\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m         )\n\u001b[1;32m-> 1127\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1128\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"attention_mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_type_ids\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         embedding_output = self.embeddings(\n\u001b[0m\u001b[0;32m    788\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"position_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, position_ids, token_type_ids, inputs_embeds, past_key_values_length, training)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"embeddings\" (type TFBertEmbeddings).\n\nValue for attr 'Tindices' of float is not in the list of allowed values: int32, int64\n\t; NodeDef: {{node ResourceGather}}; Op<name=ResourceGather; signature=resource:resource, indices:Tindices -> output:dtype; attr=batch_dims:int,default=0; attr=validate_indices:bool,default=true; attr=dtype:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true> [Op:ResourceGather]\n\nCall arguments received:\n  • input_ids=tf.Tensor(shape=(1, 0), dtype=float32)\n  • position_ids=None\n  • token_type_ids=tf.Tensor(shape=(1, 0), dtype=int32)\n  • inputs_embeds=None\n  • past_key_values_length=0\n  • training=False"
     ]
    }
   ],
   "source": [
    "#設定變數\n",
    "df_len = aud1_YF.shape[0] #新聞數\n",
    "bertvec = np.array([]) #新聞向量儲存\n",
    "\n",
    "#計算文本向量\n",
    "for i in range(df_len):\n",
    "    bertvec = np.append(bertvec, text2averege_bertvec(aud1_YF[\"bert_body\"][i]))\n",
    "bertvec = bertvec.reshape(df_len,768) #使每篇文本有各自的向量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11520"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bertvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = aud1_YF[\"bert_body\"][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['melbourne reuters australia post has successfully fieldtrialled the use of drones to deliver small packages clearing the way for test deliveries to customer homes later this year', 'the stateowned corporation said the drones will be used for the delivery of online shopping parcels and timesensitive items such as medication', 'we will put this innovative technology through its paces over the coming weeks and months to understand what it can deliver how far it can travel and ultimately how our customers could receive a parcel australia post managing director ahmed fahour said', 'postal services around the world are facing dramatic declines in their core letterdelivery business as customers turn to the internet for all forms of correspondence from billing to greeting cards', 'while australia post is the first australian company to get into the area of drone delivery in the united states online retailer amazon unveiled a drone delivery prototype in november joining competitors googl and walmartwmtstul who are also looking into the technology', '', 'australia is vast interior is one of the most sparsely populated in the world but drone delivery is unlikely to penetrate beyond the major cities amazon is prototype last year managed to fly a package only miles kms', 'australia post last year posted a a million million loss the company is first fullyear loss posting in over years and dramatic downturn from a a million million profit in the company attributed some of the loss to a per cent fall in the use of stamped letters', 'reporting by jarni blakkarly editing by eric meijer']\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.14824732e-02,  1.88410339e-01,  4.30045264e-01,\n",
       "         1.72439997e-01,  2.18442846e-01, -1.21281643e-01,\n",
       "        -3.88794386e-01,  4.34365995e-01,  2.52648963e-02,\n",
       "        -3.60528971e-01,  3.13426118e-03, -5.20747897e-01,\n",
       "         2.87111282e-02,  3.39647215e-01, -3.61451245e-02,\n",
       "         4.70918997e-01, -1.45415441e-01,  1.84280125e-01,\n",
       "        -2.88059543e-01,  1.74887497e-01,  5.57171981e-02,\n",
       "        -1.85740338e-01,  2.48345919e-01,  4.83319071e-01,\n",
       "         3.95006776e-01, -3.14991084e-01,  1.66375492e-01,\n",
       "        -1.57143173e-02, -3.59626700e-01, -6.32379781e-02,\n",
       "         4.26675032e-01, -2.09261803e-01, -1.47184285e-01,\n",
       "        -1.10457317e-01,  1.23040926e-01, -9.21108983e-02,\n",
       "         1.55168864e-02,  1.15635396e-01, -2.72290079e-01,\n",
       "        -1.30408452e-01, -6.56710400e-01, -2.88112444e-01,\n",
       "         1.28554696e-01, -1.48023918e-01, -4.44041090e-01,\n",
       "        -6.40368800e-02,  1.06219896e-02, -2.00929059e-01,\n",
       "         5.52311321e-02,  9.40183956e-02, -4.61942272e-01,\n",
       "         1.04400811e-01,  3.90799052e-02, -2.42619664e-01,\n",
       "         1.33874587e-01,  3.39693778e-01, -8.55498901e-02,\n",
       "        -7.45623435e-01, -5.19833113e-01, -1.00503399e-01,\n",
       "         4.44584567e-01,  4.18713808e-02, -9.26778588e-02,\n",
       "        -2.89447169e-01, -1.23694507e-02, -3.46687112e-01,\n",
       "         6.36146288e-02,  5.34392087e-01, -1.89628394e-01,\n",
       "        -1.29151367e-01,  1.05217436e-01, -3.31525316e-02,\n",
       "        -1.50603943e-01, -1.58312275e-01, -3.03981221e-01,\n",
       "        -3.91674856e-02, -2.52683900e-01,  7.76371770e-01,\n",
       "         4.11839242e-01, -1.69012857e-03, -2.56616032e-01,\n",
       "         2.32026474e-01, -1.89151253e-01,  3.65511760e-01,\n",
       "         2.99739856e-01,  5.20588833e-02,  2.06744031e-01,\n",
       "         3.49873704e-01, -1.43136305e-01,  4.57080747e-01,\n",
       "         4.25199750e-01, -6.30621742e-01,  1.66640542e-01,\n",
       "         1.38989909e-01,  1.87559867e-01, -5.38935704e-02,\n",
       "         1.12796646e-01, -5.61801935e-02, -1.69572823e-01,\n",
       "        -1.32172342e-02,  9.74628266e-02, -1.93687556e-01,\n",
       "        -9.37569014e-02, -4.16063412e-02,  1.19441158e-01,\n",
       "        -2.41074521e-01,  1.80235230e-01,  6.30948478e-03,\n",
       "         1.71414624e-01, -4.41375962e-02,  3.64955146e-01,\n",
       "        -2.14942559e-01, -4.85180164e-01, -5.77188464e-02,\n",
       "        -1.00014114e-01, -2.63969661e-01,  8.59862358e-02,\n",
       "         1.80198721e-01,  1.24399329e-01, -2.92786764e-01,\n",
       "         2.15647452e-01,  1.81174896e-01,  3.86046486e-02,\n",
       "         8.54622363e-01,  2.23509023e-01,  1.00003714e-02,\n",
       "        -4.37681418e-01,  3.66472707e-01, -1.93791207e-01,\n",
       "         3.89415181e-02,  1.24328804e-01,  2.03884591e-02,\n",
       "        -1.19271869e-01, -3.89934210e-01,  9.83243723e-02,\n",
       "         2.12190226e-01, -2.80767855e-01, -9.90608327e-02,\n",
       "        -8.39363516e-02,  1.23466645e-01,  1.08727465e-01,\n",
       "         6.64837624e-02,  2.62331536e-01,  1.76697442e-03,\n",
       "        -4.26340052e-02, -6.58319603e-02, -1.23489742e-01,\n",
       "        -3.07478712e-01, -5.59064032e-01,  9.95376759e-02,\n",
       "        -2.59623537e-01,  2.88750044e-01, -1.42174654e-01,\n",
       "        -7.48187321e-02,  3.17012710e-01,  1.55633826e-03,\n",
       "        -5.05725417e-01,  2.98389546e-02, -3.77799145e-01,\n",
       "        -8.37431877e-02,  1.43910215e-01,  2.20481444e-01,\n",
       "        -1.01537133e-01, -4.54604849e-01, -4.85241121e-03,\n",
       "        -2.57504752e-01,  1.01223801e-01,  2.74522460e-01,\n",
       "        -2.56611840e-01, -4.40765307e-02,  2.71520830e-03,\n",
       "         2.40964481e-02,  7.52616814e-01,  4.68613511e-02,\n",
       "         2.58237324e-01,  3.49771654e-02,  3.05051398e-01,\n",
       "         1.46378987e-01,  9.40656623e-02,  2.17438113e-01,\n",
       "        -3.83196024e-01,  4.00291492e-01, -2.79655861e-01,\n",
       "         3.20735080e-02,  3.41031010e-01, -1.31404806e-01,\n",
       "         3.51590493e-01, -3.62110244e-02,  1.57162301e-01,\n",
       "        -1.14664097e-01, -5.26692406e-01, -8.03207644e-02,\n",
       "        -5.31196397e-02, -3.05071877e-02,  1.51907105e-01,\n",
       "        -5.20398841e-01, -2.57758484e-02,  1.20925699e-01,\n",
       "        -2.09155774e-01, -2.15217124e-01, -1.46412236e-02,\n",
       "         6.17019838e-02,  6.46660999e-02,  7.51641292e-02,\n",
       "        -2.81290818e-01, -2.75520800e-01,  1.87317337e-01,\n",
       "        -8.28689364e-02, -2.67414933e-01, -7.77084100e-02,\n",
       "         1.83430538e-01,  4.79701926e-02, -9.04996512e-02,\n",
       "         1.74092327e-01,  1.60453389e-01,  2.10228248e-01,\n",
       "         8.27999785e-02, -3.36539892e-01,  1.57956504e-01,\n",
       "        -1.05874290e-01, -6.88816357e-02, -1.81551980e-01,\n",
       "         6.90212266e-02,  2.11722678e-01,  1.08476725e-01,\n",
       "         4.70175455e-01,  2.17388855e-01, -7.81805075e-01,\n",
       "         1.09715976e-01,  2.48663945e-01,  2.20062432e-02,\n",
       "        -5.43526869e-01,  4.63255223e-01, -1.89633926e-01,\n",
       "        -1.29920332e-01, -2.02307725e-01, -2.08654677e-02,\n",
       "         9.94602879e-03,  3.95836414e-01, -2.01569236e-01,\n",
       "        -1.55641595e-01,  4.18794119e-01,  1.83055856e-01,\n",
       "         4.11278933e-01, -3.10722333e-02, -2.29337659e-01,\n",
       "        -1.23137792e-01,  1.83830372e-02, -2.42613206e-01,\n",
       "        -1.44740995e-02, -4.48690777e-01, -3.01299606e-01,\n",
       "        -3.02416320e-01, -1.56788978e-01,  2.79394119e-02,\n",
       "        -7.35968622e-01, -3.36142615e-02, -4.09531188e-01,\n",
       "         6.72141735e-02,  3.08559111e-01,  8.81546893e-02,\n",
       "         3.10075883e-01,  1.94741575e-01,  1.58046913e-01,\n",
       "        -8.42923477e-03, -3.48154539e-01, -5.82485634e-01,\n",
       "        -4.70421629e-02,  5.04532109e-01,  3.25790475e-01,\n",
       "         1.42943288e-01,  5.53070482e-02,  1.20634116e-01,\n",
       "         3.01140884e-01, -6.21088064e-03,  1.19273794e-01,\n",
       "         3.56557549e-01,  1.77433296e-01,  1.95898967e-01,\n",
       "        -2.20283463e-01, -7.23834285e-02,  4.07074462e-01,\n",
       "         3.59566816e-01,  7.15793742e-03,  1.22944003e-02,\n",
       "        -3.94332135e-01,  2.26700025e-01,  1.28287628e-01,\n",
       "        -2.99294400e-01,  8.16690239e-02,  1.40380040e-01,\n",
       "         1.36035741e-02,  2.68107462e-03, -3.39280859e-01,\n",
       "         3.24567110e-01,  1.61883291e-01,  1.93310622e-01,\n",
       "         2.68713837e-01,  3.56098700e-01, -3.19613042e-01,\n",
       "        -2.02972836e-01,  1.92837451e-01,  2.75312363e-01,\n",
       "         2.18018951e-01,  4.35232435e-02, -2.24106397e-01,\n",
       "        -9.39100613e-02, -4.24536456e-01, -5.18731198e+00,\n",
       "        -6.29520525e-02, -6.34042063e-03, -4.73746714e-01,\n",
       "         4.29857765e-01, -2.58059080e-01,  4.81884618e-02,\n",
       "        -7.85614308e-02, -1.00932907e-01,  1.83184805e-02,\n",
       "         7.77258395e-02,  2.17656245e-01,  1.66528123e-01,\n",
       "        -4.55532286e-02,  1.50006020e-01, -4.71576554e-02,\n",
       "        -1.58664701e-01, -2.38285329e-01, -2.20602615e-03,\n",
       "         4.22331017e-01, -2.80195734e-02, -3.07555134e-01,\n",
       "         8.39497582e-02,  4.32305819e-02,  2.48371443e-01,\n",
       "         1.31220502e-01, -4.66696414e-01, -2.21678200e-01,\n",
       "        -1.52018314e-01,  2.10075678e-02,  1.16082208e-01,\n",
       "        -1.45800708e-01, -3.07954402e-01,  1.96019276e-01,\n",
       "         2.17116090e-01, -1.87080155e-02,  1.00489072e-01,\n",
       "        -3.75039968e-01,  1.28490196e-01, -4.83079704e-01,\n",
       "        -1.22392404e-01, -5.10962342e-01, -2.05031206e-02,\n",
       "        -1.11135766e-01,  6.51800581e-01, -1.23915327e-01,\n",
       "         4.07267843e-01,  3.18507781e-02,  1.18131240e-02,\n",
       "        -1.77259406e-02,  3.68671689e-01,  8.60732086e-02,\n",
       "        -3.68271652e-01, -3.82351846e-01,  9.51511347e-02,\n",
       "         1.75461618e-01,  1.42520931e-01,  5.70740604e-01,\n",
       "        -6.95533750e-02, -2.04163820e-01, -2.20043687e-01,\n",
       "        -7.52773837e-02, -4.74178895e-01, -2.73239993e-02,\n",
       "        -1.32607256e-01, -2.90995541e-01, -6.10064652e-01,\n",
       "         1.27229032e-01,  6.26628021e-02, -2.29149299e-01,\n",
       "        -2.13547893e-01,  2.09717552e-01, -2.80787334e-01,\n",
       "        -5.43747728e-01, -9.61704861e-02, -4.71389075e-01,\n",
       "         2.32062976e-01,  1.17019854e-01,  1.98108121e-01,\n",
       "        -1.60311995e-01, -5.20115082e-01, -1.55789830e-01,\n",
       "         1.99145507e-01, -2.02767606e-01, -2.46619499e-01,\n",
       "         4.28952615e-02, -2.57267139e-01, -2.12151068e-01,\n",
       "        -6.74337723e-02, -3.87342024e-01,  1.59051154e-01,\n",
       "         1.37842813e-01,  1.75860036e-01,  8.70204303e-03,\n",
       "         4.71690076e-01,  1.70581093e-01,  1.41080466e-01,\n",
       "        -3.64281183e-03, -2.03599627e-01, -6.95244896e-02,\n",
       "         2.40152436e-01,  1.48230587e-01,  5.59887582e-02,\n",
       "        -6.06976580e-01,  1.81760703e-01, -1.60937487e-01,\n",
       "        -5.03146988e-01,  1.73913329e-01,  1.28069774e-01,\n",
       "        -3.21838820e-01,  1.61253353e-01, -1.63253520e-01,\n",
       "         6.64765171e-02, -2.86704159e-01, -2.99026607e-01,\n",
       "        -3.26188992e-01, -5.44389599e-02,  3.21716838e-01,\n",
       "         3.26443523e-01, -2.51618958e-01, -3.56560463e-01,\n",
       "         5.13316256e-01, -3.56319058e-01, -4.15823562e-02,\n",
       "        -2.04332386e-01,  1.67979571e-01, -2.00097789e-01,\n",
       "         1.19472326e-01,  5.08804602e-01, -8.20552719e-03,\n",
       "        -1.10410317e-01, -1.89548089e-01, -7.68659439e-02,\n",
       "         3.51603039e-01, -6.34743241e-03, -2.62876357e-02,\n",
       "         4.35636175e-02, -1.02884718e-01, -1.18932990e-01,\n",
       "         1.96980126e-01, -1.14078641e-01,  3.85158198e-01,\n",
       "        -4.58705600e-02,  1.34584452e-01,  1.50216419e-01,\n",
       "         1.60140007e-01, -1.84405053e-01,  3.59986934e-01,\n",
       "        -1.19027911e-01, -1.36828090e-01, -2.78286790e-01,\n",
       "        -3.72760810e-02, -2.48218557e-01, -3.03428426e-01,\n",
       "         3.72236897e-01,  2.27963361e-01,  7.95422952e-02,\n",
       "        -1.09036482e-01, -1.70205829e-01, -7.31238359e-01,\n",
       "         3.65427264e-01,  9.66644232e-02, -6.39896091e-02,\n",
       "         3.41881604e-01, -3.06210474e-01,  5.03161293e-01,\n",
       "        -4.88421047e-02,  3.87500479e-01,  3.33716941e-01,\n",
       "         4.59399845e-03, -9.42750591e-02, -4.34110794e-01,\n",
       "         4.50924018e-02, -2.61004859e-01, -5.40078956e-02,\n",
       "         6.23800639e-01,  1.36480178e-01, -1.70995069e-01,\n",
       "        -3.19039304e-01,  3.36167083e-01, -8.78592880e-02,\n",
       "         5.37408553e-02,  4.73556416e-02,  7.31709482e-02,\n",
       "         7.12900426e-02,  8.23094932e-02,  4.30027647e-01,\n",
       "        -2.41637869e-01, -7.21689175e-02,  1.91365361e-01,\n",
       "        -2.55234118e-01,  4.47720275e-01, -2.67364237e-01,\n",
       "        -1.07797028e-01, -3.57367837e-01, -1.23151137e-01,\n",
       "         4.81816888e-01,  2.31169515e-01, -8.85286564e-03,\n",
       "         1.51585466e-01, -4.75251960e-02, -1.78304196e-02,\n",
       "        -2.65886600e-01,  1.21848085e-01, -4.53624414e-02,\n",
       "        -1.57225879e-02, -4.97956952e-02, -2.10750644e-02,\n",
       "        -2.04951299e-01, -1.91998015e-01, -2.26857592e-01,\n",
       "        -7.09367700e-02, -1.26407204e-01,  1.94395821e-01,\n",
       "        -8.87248489e-02, -5.73914944e-01, -1.94366121e-02,\n",
       "         2.38715577e-01, -3.19290235e-01,  1.58220402e-01,\n",
       "         7.61661102e-02, -1.62837076e-01,  1.52498425e-01,\n",
       "         9.75335385e-02,  1.33411147e-01, -1.48346434e-01,\n",
       "        -8.57062986e-02, -2.58752356e-01, -1.89108368e-01,\n",
       "        -1.96528748e-01,  1.08867492e-02, -6.45764106e-01,\n",
       "         1.26733989e-01,  1.14078004e-01, -3.10006311e-01,\n",
       "         2.52763816e-01,  1.16259190e-01, -6.54795940e-01,\n",
       "        -8.18485422e-02, -9.03364703e-02, -1.86795776e-02,\n",
       "        -8.62895269e-02, -3.05536361e-01, -4.24401449e-01,\n",
       "         8.14938353e-02,  2.85509156e-01, -7.79826124e-02,\n",
       "         2.03953389e-01, -6.06340560e-02,  4.78296615e-01,\n",
       "         1.70935079e-02,  1.05300274e-01,  2.72172320e-01,\n",
       "        -1.72405469e-01,  4.90686347e-02, -1.47943565e-01,\n",
       "        -1.43407503e-01, -1.38843429e-01, -4.55390796e-01,\n",
       "        -1.09541119e-01, -5.58574411e-02,  1.97438697e-01,\n",
       "        -2.93608595e-01,  2.76504091e-01,  3.73773274e-01,\n",
       "         1.46632124e-01, -1.27314418e-01, -1.16872097e-01,\n",
       "        -8.48758721e-02, -4.40319824e-01,  8.31474607e-03,\n",
       "         1.94150275e-01, -1.16725467e-02,  2.05560211e-01,\n",
       "         4.71301485e-01,  1.28506672e-01, -3.72583557e-01,\n",
       "        -9.29147081e-02,  2.21648311e-01,  4.22568641e-02,\n",
       "        -1.33111825e-02,  5.43530716e-02,  9.85390697e-02,\n",
       "        -2.39700152e-01,  4.02251993e-01, -7.88215346e-02,\n",
       "         1.73700231e-02,  2.35595050e-01, -5.78410831e-02,\n",
       "         4.37655705e-02,  6.40668772e-01,  1.75935862e-01,\n",
       "         1.03979928e-01, -2.08618775e-01, -2.94331315e-01,\n",
       "         3.70960010e-01,  2.29645753e-01, -1.07771877e-01,\n",
       "         2.71595335e-01, -2.26589688e-01, -7.00014712e-02,\n",
       "        -9.50713912e-02,  5.32577384e-01,  5.17194056e-02,\n",
       "        -2.25596123e-01,  3.07028452e-01, -9.55031010e-03,\n",
       "        -2.45674650e-01, -1.03778072e-01, -2.09144151e-01,\n",
       "         4.50336504e-02, -3.93517555e-01,  1.53303537e-01,\n",
       "         2.89336172e-01, -1.62049832e-01, -1.55297811e-01,\n",
       "         9.15236734e-02, -3.32842660e-02,  2.61511355e-01,\n",
       "         1.89206077e-01, -2.84317143e-01,  4.97682747e-01,\n",
       "         5.27374281e-01, -2.47300062e-01,  4.74628537e-01,\n",
       "        -7.90017535e-03,  1.32505958e-01, -1.24420420e-01,\n",
       "         1.07088314e-01,  1.02166870e-01, -2.79088605e-01,\n",
       "         4.11517115e-01, -5.25514259e-02,  6.15012464e-01,\n",
       "         1.08561358e-01,  2.73871669e-02, -1.29624192e-01,\n",
       "         1.05396288e-01,  4.67418176e-03,  3.69651531e-01,\n",
       "         1.26826185e-01, -1.35103345e-01,  2.36802488e-01,\n",
       "         3.74117334e-01,  3.07269634e-01,  4.13109156e-01,\n",
       "         3.02964830e-01,  1.19551877e-02,  2.73612951e-01,\n",
       "         6.22096952e-01,  3.61542699e-01,  3.84105385e-01,\n",
       "        -1.78612147e-01, -9.97048845e-02, -1.66030607e-01,\n",
       "         9.74330139e-02,  2.48509737e-01,  7.02145199e-01,\n",
       "        -7.03763237e-02,  4.60917297e-01,  1.91217000e-01,\n",
       "         1.40236501e-01,  3.71141972e-01, -6.88825682e-01,\n",
       "        -4.32623918e-01,  3.94695452e-02,  6.25038145e-01,\n",
       "        -2.72006948e-01, -1.08791417e-01, -7.72383325e-03,\n",
       "        -1.65310908e-01,  4.35686499e-02, -2.41237256e-01,\n",
       "        -1.93270096e-01, -1.10622452e-01,  1.89353011e-01,\n",
       "        -2.26336376e-01, -1.81545133e-01,  1.16598754e-01,\n",
       "         3.18677309e-01,  5.93720016e-03, -1.77967120e-01,\n",
       "        -3.49525927e-01, -3.18312677e-02, -1.13661603e-01,\n",
       "        -7.28824634e-02, -3.66362021e-01, -1.29755205e-02,\n",
       "        -3.99095024e-01, -2.82366308e-01, -2.50846795e-01,\n",
       "        -5.96689374e-02,  5.11358035e-01,  4.50099113e-02,\n",
       "        -2.70654014e-01, -4.81555981e-01,  1.75803053e-01,\n",
       "        -5.12377605e-02,  4.54152076e-01,  3.01518716e-01,\n",
       "         6.12538841e-02, -1.81208045e-01, -1.44986281e-01,\n",
       "         3.01376611e-01,  3.35138822e-01,  8.70023751e-02,\n",
       "         1.87183529e-01,  1.99398218e-01, -3.07496409e-01,\n",
       "        -1.60190635e-01,  5.67243626e-01,  1.24247140e-01,\n",
       "        -5.86065126e-01,  2.03890870e-01, -3.57408828e-01,\n",
       "        -2.11249149e-02,  3.97776082e-01,  2.48273773e-01,\n",
       "        -1.29863511e-01, -1.86125557e-01, -4.13076405e-01,\n",
       "        -1.42301178e-01,  9.42944961e-02, -2.89130184e-01,\n",
       "        -2.44616274e-01,  3.03787929e-02,  3.56930716e-02,\n",
       "         4.94898819e-01,  7.36090137e-02,  2.47977909e-01,\n",
       "        -2.00159552e-01,  1.64989011e-01, -1.60416013e-01,\n",
       "         1.59939139e-01, -4.20722709e-02,  2.38074352e-02,\n",
       "        -2.87445106e-01,  3.51451172e-02, -1.27942576e-02,\n",
       "         1.03149218e-01,  1.06496431e-01,  3.30031278e-01,\n",
       "        -6.20302420e-02, -2.53555963e-01,  4.81339210e-01,\n",
       "         8.44040578e-02, -8.93558621e-02, -6.68476318e-02,\n",
       "        -7.38294232e-01, -3.67472330e-01, -2.88681828e-01,\n",
       "        -1.12371113e-01, -1.02931529e-01, -3.82974743e-01,\n",
       "         1.96677220e-01, -3.05307556e-01, -3.08250471e-01,\n",
       "        -2.54103235e-01,  2.14312613e-02,  1.10300831e-01]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2averege_bertvec(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['melbourne', 'reuters', 'australia', 'post', 'has', 'successfully', 'field', '##tri', '##alle', '##d', 'the', 'use', 'of', 'drones', 'to', 'deliver', 'small', 'packages', 'clearing', 'the', 'way', 'for', 'test', 'deliveries', 'to', 'customer', 'homes', 'later', 'this', 'year']\n",
      "[4940, 26665, 2660, 2695, 2038, 5147, 2492, 18886, 24164, 2094, 1996, 2224, 1997, 24633, 2000, 8116, 2235, 14555, 8430, 1996, 2126, 2005, 3231, 23534, 2000, 8013, 5014, 2101, 2023, 2095]\n",
      "tf.Tensor(\n",
      "[ 4940 26665  2660  2695  2038  5147  2492 18886 24164  2094  1996  2224\n",
      "  1997 24633  2000  8116  2235 14555  8430  1996  2126  2005  3231 23534\n",
      "  2000  8013  5014  2101  2023  2095], shape=(30,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 4940 26665  2660  2695  2038  5147  2492 18886 24164  2094  1996  2224\n",
      "   1997 24633  2000  8116  2235 14555  8430  1996  2126  2005  3231 23534\n",
      "   2000  8013  5014  2101  2023  2095]], shape=(1, 30), dtype=int32)\n",
      "['the', 'state', '##own', '##ed', 'corporation', 'said', 'the', 'drones', 'will', 'be', 'used', 'for', 'the', 'delivery', 'of', 'online', 'shopping', 'parcels', 'and', 'times', '##ens', '##itive', 'items', 'such', 'as', 'medication']\n",
      "[1996, 2110, 12384, 2098, 3840, 2056, 1996, 24633, 2097, 2022, 2109, 2005, 1996, 6959, 1997, 3784, 6023, 28998, 1998, 2335, 6132, 13043, 5167, 2107, 2004, 14667]\n",
      "tf.Tensor(\n",
      "[ 1996  2110 12384  2098  3840  2056  1996 24633  2097  2022  2109  2005\n",
      "  1996  6959  1997  3784  6023 28998  1998  2335  6132 13043  5167  2107\n",
      "  2004 14667], shape=(26,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1996  2110 12384  2098  3840  2056  1996 24633  2097  2022  2109  2005\n",
      "   1996  6959  1997  3784  6023 28998  1998  2335  6132 13043  5167  2107\n",
      "   2004 14667]], shape=(1, 26), dtype=int32)\n",
      "['we', 'will', 'put', 'this', 'innovative', 'technology', 'through', 'its', 'paces', 'over', 'the', 'coming', 'weeks', 'and', 'months', 'to', 'understand', 'what', 'it', 'can', 'deliver', 'how', 'far', 'it', 'can', 'travel', 'and', 'ultimately', 'how', 'our', 'customers', 'could', 'receive', 'a', 'parcel', 'australia', 'post', 'managing', 'director', 'ahmed', 'fa', '##ho', '##ur', 'said']\n",
      "[2057, 2097, 2404, 2023, 9525, 2974, 2083, 2049, 24785, 2058, 1996, 2746, 3134, 1998, 2706, 2000, 3305, 2054, 2009, 2064, 8116, 2129, 2521, 2009, 2064, 3604, 1998, 4821, 2129, 2256, 6304, 2071, 4374, 1037, 20463, 2660, 2695, 6605, 2472, 10208, 6904, 6806, 3126, 2056]\n",
      "tf.Tensor(\n",
      "[ 2057  2097  2404  2023  9525  2974  2083  2049 24785  2058  1996  2746\n",
      "  3134  1998  2706  2000  3305  2054  2009  2064  8116  2129  2521  2009\n",
      "  2064  3604  1998  4821  2129  2256  6304  2071  4374  1037 20463  2660\n",
      "  2695  6605  2472 10208  6904  6806  3126  2056], shape=(44,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2057  2097  2404  2023  9525  2974  2083  2049 24785  2058  1996  2746\n",
      "   3134  1998  2706  2000  3305  2054  2009  2064  8116  2129  2521  2009\n",
      "   2064  3604  1998  4821  2129  2256  6304  2071  4374  1037 20463  2660\n",
      "   2695  6605  2472 10208  6904  6806  3126  2056]], shape=(1, 44), dtype=int32)\n",
      "['postal', 'services', 'around', 'the', 'world', 'are', 'facing', 'dramatic', 'declines', 'in', 'their', 'core', 'letter', '##del', '##iver', '##y', 'business', 'as', 'customers', 'turn', 'to', 'the', 'internet', 'for', 'all', 'forms', 'of', 'correspondence', 'from', 'billing', 'to', 'greeting', 'cards']\n",
      "[10690, 2578, 2105, 1996, 2088, 2024, 5307, 6918, 26451, 1999, 2037, 4563, 3661, 9247, 16402, 2100, 2449, 2004, 6304, 2735, 2000, 1996, 4274, 2005, 2035, 3596, 1997, 11061, 2013, 25640, 2000, 14806, 5329]\n",
      "tf.Tensor(\n",
      "[10690  2578  2105  1996  2088  2024  5307  6918 26451  1999  2037  4563\n",
      "  3661  9247 16402  2100  2449  2004  6304  2735  2000  1996  4274  2005\n",
      "  2035  3596  1997 11061  2013 25640  2000 14806  5329], shape=(33,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[10690  2578  2105  1996  2088  2024  5307  6918 26451  1999  2037  4563\n",
      "   3661  9247 16402  2100  2449  2004  6304  2735  2000  1996  4274  2005\n",
      "   2035  3596  1997 11061  2013 25640  2000 14806  5329]], shape=(1, 33), dtype=int32)\n",
      "['while', 'australia', 'post', 'is', 'the', 'first', 'australian', 'company', 'to', 'get', 'into', 'the', 'area', 'of', 'drone', 'delivery', 'in', 'the', 'united', 'states', 'online', 'retailer', 'amazon', 'unveiled', 'a', 'drone', 'delivery', 'prototype', 'in', 'november', 'joining', 'competitors', 'goo', '##gl', 'and', 'wal', '##mart', '##w', '##mt', '##st', '##ul', 'who', 'are', 'also', 'looking', 'into', 'the', 'technology']\n",
      "[2096, 2660, 2695, 2003, 1996, 2034, 2827, 2194, 2000, 2131, 2046, 1996, 2181, 1997, 18465, 6959, 1999, 1996, 2142, 2163, 3784, 20196, 9733, 11521, 1037, 18465, 6959, 8773, 1999, 2281, 5241, 10159, 27571, 23296, 1998, 24547, 22345, 2860, 20492, 3367, 5313, 2040, 2024, 2036, 2559, 2046, 1996, 2974]\n",
      "tf.Tensor(\n",
      "[ 2096  2660  2695  2003  1996  2034  2827  2194  2000  2131  2046  1996\n",
      "  2181  1997 18465  6959  1999  1996  2142  2163  3784 20196  9733 11521\n",
      "  1037 18465  6959  8773  1999  2281  5241 10159 27571 23296  1998 24547\n",
      " 22345  2860 20492  3367  5313  2040  2024  2036  2559  2046  1996  2974], shape=(48,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2096  2660  2695  2003  1996  2034  2827  2194  2000  2131  2046  1996\n",
      "   2181  1997 18465  6959  1999  1996  2142  2163  3784 20196  9733 11521\n",
      "   1037 18465  6959  8773  1999  2281  5241 10159 27571 23296  1998 24547\n",
      "  22345  2860 20492  3367  5313  2040  2024  2036  2559  2046  1996  2974]], shape=(1, 48), dtype=int32)\n",
      "['australia', 'is', 'vast', 'interior', 'is', 'one', 'of', 'the', 'most', 'sparsely', 'populated', 'in', 'the', 'world', 'but', 'drone', 'delivery', 'is', 'unlikely', 'to', 'penetrate', 'beyond', 'the', 'major', 'cities', 'amazon', 'is', 'prototype', 'last', 'year', 'managed', 'to', 'fly', 'a', 'package', 'only', 'miles', 'km', '##s']\n",
      "[2660, 2003, 6565, 4592, 2003, 2028, 1997, 1996, 2087, 24961, 10357, 1999, 1996, 2088, 2021, 18465, 6959, 2003, 9832, 2000, 19136, 3458, 1996, 2350, 3655, 9733, 2003, 8773, 2197, 2095, 3266, 2000, 4875, 1037, 7427, 2069, 2661, 2463, 2015]\n",
      "tf.Tensor(\n",
      "[ 2660  2003  6565  4592  2003  2028  1997  1996  2087 24961 10357  1999\n",
      "  1996  2088  2021 18465  6959  2003  9832  2000 19136  3458  1996  2350\n",
      "  3655  9733  2003  8773  2197  2095  3266  2000  4875  1037  7427  2069\n",
      "  2661  2463  2015], shape=(39,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2660  2003  6565  4592  2003  2028  1997  1996  2087 24961 10357  1999\n",
      "   1996  2088  2021 18465  6959  2003  9832  2000 19136  3458  1996  2350\n",
      "   3655  9733  2003  8773  2197  2095  3266  2000  4875  1037  7427  2069\n",
      "   2661  2463  2015]], shape=(1, 39), dtype=int32)\n",
      "['australia', 'post', 'last', 'year', 'posted', 'a', 'a', 'million', 'million', 'loss', 'the', 'company', 'is', 'first', 'fully', '##ear', 'loss', 'posting', 'in', 'over', 'years', 'and', 'dramatic', 'down', '##turn', 'from', 'a', 'a', 'million', 'million', 'profit', 'in', 'the', 'company', 'attributed', 'some', 'of', 'the', 'loss', 'to', 'a', 'per', 'cent', 'fall', 'in', 'the', 'use', 'of', 'stamped', 'letters']\n",
      "[2660, 2695, 2197, 2095, 6866, 1037, 1037, 2454, 2454, 3279, 1996, 2194, 2003, 2034, 3929, 14644, 3279, 14739, 1999, 2058, 2086, 1998, 6918, 2091, 22299, 2013, 1037, 1037, 2454, 2454, 5618, 1999, 1996, 2194, 7108, 2070, 1997, 1996, 3279, 2000, 1037, 2566, 9358, 2991, 1999, 1996, 2224, 1997, 20834, 4144]\n",
      "tf.Tensor(\n",
      "[ 2660  2695  2197  2095  6866  1037  1037  2454  2454  3279  1996  2194\n",
      "  2003  2034  3929 14644  3279 14739  1999  2058  2086  1998  6918  2091\n",
      " 22299  2013  1037  1037  2454  2454  5618  1999  1996  2194  7108  2070\n",
      "  1997  1996  3279  2000  1037  2566  9358  2991  1999  1996  2224  1997\n",
      " 20834  4144], shape=(50,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2660  2695  2197  2095  6866  1037  1037  2454  2454  3279  1996  2194\n",
      "   2003  2034  3929 14644  3279 14739  1999  2058  2086  1998  6918  2091\n",
      "  22299  2013  1037  1037  2454  2454  5618  1999  1996  2194  7108  2070\n",
      "   1997  1996  3279  2000  1037  2566  9358  2991  1999  1996  2224  1997\n",
      "  20834  4144]], shape=(1, 50), dtype=int32)\n",
      "['reporting', 'by', 'jar', '##ni', 'b', '##lak', '##kar', '##ly', 'editing', 'by', 'eric', 'mei', '##jer']\n",
      "[7316, 2011, 15723, 3490, 1038, 23451, 6673, 2135, 9260, 2011, 4388, 19734, 20009]\n",
      "tf.Tensor(\n",
      "[ 7316  2011 15723  3490  1038 23451  6673  2135  9260  2011  4388 19734\n",
      " 20009], shape=(13,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 7316  2011 15723  3490  1038 23451  6673  2135  9260  2011  4388 19734\n",
      "  20009]], shape=(1, 13), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "wordvec = np.array([])\n",
    "text_vec = np.array([])\n",
    "word_count = 0\n",
    "                \n",
    "for segment in eval(text):\n",
    "    \n",
    "        tokens = tokenizer.tokenize(segment)                #分割句字中的單字，看不懂得bert會補上萬用字元\n",
    "        print(tokens)\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(tokens) #將單字轉換為bert對應的詞id\n",
    "        print(token_ids)\n",
    "        token_ids = tf.convert_to_tensor(token_ids)         #將id轉為tensor表示(詞數,)\n",
    "        print(token_ids)\n",
    "        token_ids = tf.reshape(token_ids, [1, -1 ])         #reshape(1,詞數)\n",
    "        print(token_ids)\n",
    "\n",
    "        output = bert_model(token_ids)                      #輸入至bert模型中\\\n",
    "        segment_vec = output[0][0].numpy()                  #將tensor轉為numpy，比較好用> <\n",
    "        word_count += segment_vec.shape[0]                  #統計字數\n",
    "        wordvec = np.append(wordvec, segment_vec)           #將所有句子append到一個np.array。缺點會全部變成一維表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['melbourne reuters australia post has successfully fieldtrialled the use of drones to deliver small packages clearing the way for test deliveries to customer homes later this year', 'the stateowned corporation said the drones will be used for the delivery of online shopping parcels and timesensitive items such as medication', 'we will put this innovative technology through its paces over the coming weeks and months to understand what it can deliver how far it can travel and ultimately how our customers could receive a parcel australia post managing director ahmed fahour said', 'postal services around the world are facing dramatic declines in their core letterdelivery business as customers turn to the internet for all forms of correspondence from billing to greeting cards', 'while australia post is the first australian company to get into the area of drone delivery in the united states online retailer amazon unveiled a drone delivery prototype in november joining competitors googl and walmartwmtstul who are also looking into the technology', '', 'australia is vast interior is one of the most sparsely populated in the world but drone delivery is unlikely to penetrate beyond the major cities amazon is prototype last year managed to fly a package only miles kms', 'australia post last year posted a a million million loss the company is first fullyear loss posting in over years and dramatic downturn from a a million million profit in the company attributed some of the loss to a per cent fall in the use of stamped letters', 'reporting by jarni blakkarly editing by eric meijer']\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
